{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Approach </b>\n",
    "\n",
    "1) Use Deep Neural networks - Generate embeddings for signatures genuine and forgery use a triplet loss mining approach to separate the features of forged signatures from genuine.\n",
    "2) Use Logistic regression for decisioning - use the embedding outputs from step1 and use these as features to train a logistics regression model to output the decision of genuine or forgery.\n",
    "   * A Deep Neural Network Model for decision would have worked better "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style=\"color: red;\">TODO </b>\n",
    "1) Add signatures from dataset1 to dataset2 mainly related to background color <br>\n",
    "2) Understand how to setup tensorflow GPU. Currently using Tensorflow CPU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Tuning </b><p>\n",
    "To try\n",
    "* _compute_loss_sq change margin from 0.5 to 0.6   8/3 - Trying (need to retrain)\n",
    "* Try AutoKeras for hyper parameter tuning.\n",
    "* Try sklearn skitOptimizer\n",
    "* Try AutoGluon https://towardsdatascience.com/autogluon-deep-learning-automl-5cdb4e2388ec \n",
    "\n",
    "* Recalculate all the weights for ResNet50\n",
    "* Try MXNet is faster than tensorflow.\n",
    "* Add a custom layer which included the forgery decision to determine the weights (maybe use a MixMaxScaler to maximize the diff range)\n",
    "* Try a VGG16 with triplet loss mining.\n",
    "* Build a custom layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from tensorflow.keras import applications  ##Tensor flow version used 2.4.1\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.applications import resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageDimensions = (224,224,3)\n",
    "\n",
    "## Location to save the DNN model to generate Embeddings.\n",
    "filename = '/notebooks/capstone/models/embeddings-res32'        ##DNN Embeddings models save location\n",
    "filename2 = '/notebooks/capstone/models/siamesenetwork-res32'   ##DNN Siamesemodelsave location\n",
    "\n",
    "## Locations to pickle the generated embeddings for training data using trained model. \n",
    "#pFile_embeddings_train = \"/notebooks/capstone/train_embeddings.pickle\"  ##cosine\n",
    "pFile_embeddings_train = \"/notebooks/capstone/train_embeddings_k.pickle\"  ##kmean distance\n",
    "\n",
    "## Locations to pickle the generated embeddings for test data using trained model. \n",
    "pFile_embeddings_tst = \"/notebooks/capstone/tst_embeddings_k.pickle\"\n",
    "\n",
    "##LogisticRegression model saved.\n",
    "#pFile_lrmodel = \"/notebooks/capstone/train_lr_c.pickle\" #cosine\n",
    "pFile_lrmodel = \"/notebooks/capstone/train_lr_k.pickle\"  #squared distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Utility functions</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(filename):\n",
    "    \"\"\"\n",
    "    Load the specified file as a JPEG image, preprocess it and\n",
    "    resize it to the target shape.\n",
    "    \"\"\"\n",
    "\n",
    "    image_string = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_png(image_string, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, imageDimensions[:-1])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_triplets_train( anchor, positive, negative):\n",
    "    \"\"\"\n",
    "    Given the filenames corresponding to the three images, load and\n",
    "    preprocess them.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        preprocess_image(anchor),\n",
    "        preprocess_image(positive),\n",
    "        preprocess_image(negative),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_triplets(personId, anchor, positive, negative, isGenuine, anchor_path, positive_path, negative_path):\n",
    "    \"\"\"\n",
    "    Given the filenames corresponding to the three images, load and\n",
    "    preprocess them.\n",
    "    \"\"\"\n",
    "    print(\">>> Anchor\", anchor)\n",
    "\n",
    "    return (\n",
    "        personId,\n",
    "        preprocess_image(anchor),\n",
    "        preprocess_image(positive),\n",
    "        preprocess_image(negative),\n",
    "        isGenuine,\n",
    "        anchor_path, positive_path, negative_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(images_dataset):\n",
    "    \"\"\"Visualize a few triplets from the supplied batches.\"\"\"\n",
    "\n",
    "    def showImages(ax, image):\n",
    "        for i in range(3):\n",
    "            ax[i].imshow(image[i])\n",
    "            ax[i].get_xaxis().set_visible(False)\n",
    "            ax[i].get_yaxis().set_visible(False)\n",
    "\n",
    "    rows = len(images_dataset)\n",
    "    images = list(images_dataset.as_numpy_iterator())\n",
    "    fig, axs = plt.subplots(rows,3, sharex=True, sharey=True, figsize=(30,30))\n",
    "    for x in range(rows):\n",
    "         anchor, positive, negative = images[x][0],images[x][1],images[x][2]\n",
    "         showImages(axs[x], (anchor, positive, negative))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Load training and test data </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       company  personId person        fileName   relPath  Genuine  forged\n",
      "0    Acme Corp         1   Erin      001_01.PNG       001        1       0\n",
      "887  Acme Corp         1   Erin  0119001_01.png  001_forg        0       1\n",
      "894  Acme Corp         1   Erin  0201001_04.png  001_forg        0       1\n",
      "888  Acme Corp         1   Erin  0119001_02.png  001_forg        0       1\n",
      "889  Acme Corp         1   Erin  0119001_03.png  001_forg        0       1\n",
      "(1649, 7)\n"
     ]
    }
   ],
   "source": [
    "basePath = \"/notebooks/capstone/dataset/dataset2/sign_data\"\n",
    "data_train = pd.read_csv(basePath + \"/train/train_clean.csv\")\n",
    "data_train.sort_values(by=\"personId\", inplace=True)\n",
    "print(data_train.head())\n",
    "print(data_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           company  personId person        fileName   relPath  Genuine  forged\n",
      "0    AI Novice Inc        49     IE      01_049.png       049        1       0\n",
      "255  AI Novice Inc        49     IE  02_0114049.PNG  049_forg        0       1\n",
      "256  AI Novice Inc        49     IE  02_0206049.PNG  049_forg        0       1\n",
      "257  AI Novice Inc        49     IE  02_0210049.PNG  049_forg        0       1\n",
      "252  AI Novice Inc        49     IE  01_0114049.PNG  049_forg        0       1\n",
      "258  AI Novice Inc        49     IE  03_0114049.PNG  049_forg        0       1\n",
      "259  AI Novice Inc        49     IE  03_0206049.PNG  049_forg        0       1\n",
      "260  AI Novice Inc        49     IE  03_0210049.PNG  049_forg        0       1\n",
      "261  AI Novice Inc        49     IE  04_0114049.PNG  049_forg        0       1\n",
      "262  AI Novice Inc        49     IE  04_0206049.PNG  049_forg        0       1\n",
      "263  AI Novice Inc        49     IE  04_0210049.PNG  049_forg        0       1\n",
      "254  AI Novice Inc        49     IE  01_0210049.PNG  049_forg        0       1\n",
      "253  AI Novice Inc        49     IE  01_0206049.PNG  049_forg        0       1\n",
      "9    AI Novice Inc        49     IE      10_049.png       049        1       0\n",
      "1    AI Novice Inc        49     IE      02_049.png       049        1       0\n",
      "2    AI Novice Inc        49     IE      03_049.png       049        1       0\n",
      "11   AI Novice Inc        49     IE      12_049.png       049        1       0\n",
      "3    AI Novice Inc        49     IE      04_049.png       049        1       0\n",
      "4    AI Novice Inc        49     IE      05_049.png       049        1       0\n",
      "5    AI Novice Inc        49     IE      06_049.png       049        1       0\n",
      "(500, 7)\n"
     ]
    }
   ],
   "source": [
    "data_test = pd.read_csv(basePath + \"/test/test_clean.csv\")\n",
    "data_test.sort_values(by=\"personId\", inplace=True)\n",
    "print(data_test.head(20))\n",
    "print(data_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Prepare training data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorizeImages(df, typeOfData):\n",
    "    personIds = df[\"personId\"].unique()\n",
    "    anchor_imgs = []\n",
    "    postive_imgs = []\n",
    "    negative_imgs = []\n",
    "    for p in personIds:\n",
    "        genuine = df[(df.personId==p) & (df.Genuine==1)]\n",
    "        forg = df[(df.personId==p) & (df.Genuine==0)]\n",
    "        anchor_img = basePath+\"/\"+typeOfData+\"/\"+genuine.iloc[0].relPath + \"/\"+genuine.iloc[0].fileName  \n",
    "        for g in genuine[1:].index:\n",
    "            pos_img= basePath+\"/\"+typeOfData+\"/\"+genuine.loc[g].relPath + \"/\"+genuine.loc[g].fileName  \n",
    "            for f in forg.index:\n",
    "                neg_img =  basePath+\"/\"+typeOfData+\"/\"+forg.loc[f].relPath + \"/\"+forg.loc[f].fileName  \n",
    "                anchor_imgs.append(anchor_img)\n",
    "                postive_imgs.append(pos_img)\n",
    "                negative_imgs.append(neg_img)\n",
    "    \n",
    "    return anchor_imgs,postive_imgs,negative_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_images,positive_images,negative_images = categorizeImages(data_train, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Anchor Tensor(\"args_0:0\", shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "anchor_dataset = tf.data.Dataset.from_tensor_slices(anchor_images)\n",
    "positive_dataset  = tf.data.Dataset.from_tensor_slices(positive_images)\n",
    "negative_dataset  = tf.data.Dataset.from_tensor_slices(negative_images)\n",
    "dataset = tf.data.Dataset.zip((anchor_dataset, positive_dataset, negative_dataset))\n",
    "dataset = dataset.shuffle(buffer_size=1024)\n",
    "dataset = dataset.map(preprocess_triplets_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now split our dataset in train and validation.\n",
    "image_count = len(anchor_dataset)\n",
    "train_dataset = dataset.take(round(image_count * 0.8))\n",
    "val_dataset = dataset.skip(round(image_count * 0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize(train_dataset.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.batch(32, drop_remainder=False)\n",
    "train_dataset = train_dataset.prefetch(8)\n",
    "\n",
    "val_dataset = val_dataset.batch(32, drop_remainder=False)\n",
    "val_dataset = val_dataset.prefetch(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Define Evaluation Functions</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare each positive each positive in the set and and each negative against all other positives\n",
    "def categorizeTestImages(df, typeOfData):\n",
    "    personIds = df[\"personId\"].unique()\n",
    "    anchor_imgs = []\n",
    "    postive_imgs = []\n",
    "    toCompare_imgs = []\n",
    "    isGenuine = []\n",
    "    personId = []\n",
    "    for p in personIds:\n",
    "        genuine = df[(df.personId==p) & (df.Genuine==1)]\n",
    "        forg = df[(df.personId==p) & (df.Genuine==0)]\n",
    "        anchor_img = basePath+\"/\"+typeOfData+\"/\"+genuine.iloc[0].relPath + \"/\"+genuine.iloc[0].fileName  \n",
    "        for g in genuine[1:].index:\n",
    "            pos_img= basePath+\"/\"+typeOfData+\"/\"+genuine.loc[g].relPath + \"/\"+genuine.loc[g].fileName  \n",
    "            #Compare this with all forgeries\n",
    "            for f in forg.index:\n",
    "                toCompareImg =  basePath+\"/\"+typeOfData+\"/\"+forg.loc[f].relPath + \"/\"+forg.loc[f].fileName \n",
    "                personId.append(p)\n",
    "                anchor_imgs.append(anchor_img)\n",
    "                postive_imgs.append(pos_img)\n",
    "                toCompare_imgs.append(toCompareImg)\n",
    "                isGenuine.append(False)\n",
    "                \n",
    "            # Compare current postive with all other positives besides the anchor\n",
    "            for f in genuine[1:].index:\n",
    "                toCompareImg =  basePath+\"/\"+typeOfData+\"/\"+genuine.loc[f].relPath + \"/\"+genuine.loc[f].fileName  \n",
    "                if ( pos_img != toCompareImg):\n",
    "                    personId.append(p)\n",
    "                    anchor_imgs.append(anchor_img)\n",
    "                    postive_imgs.append(pos_img)\n",
    "                    toCompare_imgs.append(toCompareImg)\n",
    "                    isGenuine.append(True)    \n",
    "    return personId, anchor_imgs,postive_imgs,toCompare_imgs, isGenuine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize(tst_dataset.take(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareEvaluationData(data_df, typeOfData):\n",
    "    personId, anchor_images,positive_images,toCompare_imgs, isGenuine = categorizeTestImages(data_df, typeOfData)\n",
    "    personId_dataset = tf.data.Dataset.from_tensor_slices(personId)\n",
    "    anchor_dataset = tf.data.Dataset.from_tensor_slices(anchor_images)\n",
    "    positive_dataset  = tf.data.Dataset.from_tensor_slices(positive_images)\n",
    "    toCompare_imgs_dataset  = tf.data.Dataset.from_tensor_slices(toCompare_imgs)\n",
    "    isGenuine_dataset  = tf.data.Dataset.from_tensor_slices(isGenuine)\n",
    "\n",
    "    anchor_path_dataset = tf.data.Dataset.from_tensor_slices(anchor_images)\n",
    "    positive_path_dataset  = tf.data.Dataset.from_tensor_slices(positive_images)\n",
    "    toCompare_imgs_path_dataset  = tf.data.Dataset.from_tensor_slices(toCompare_imgs)\n",
    "\n",
    "    dataset = tf.data.Dataset.zip((personId_dataset, anchor_dataset, positive_dataset, toCompare_imgs_dataset, isGenuine_dataset, anchor_path_dataset, positive_path_dataset, toCompare_imgs_path_dataset))\n",
    "    ##dataset = dataset.shuffle(buffer_size=1024)\n",
    "    dataset = dataset.map(preprocess_triplets)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Prepare model for Triplet Loss Mining </b> to compute the weights to generate embeddings for a signature specimen which will be closer to the genuine anchor signature and furthest from a forgery signature<br><br>\n",
    "<b>Prepare Model Architecture</b>\n",
    "Setting up the embedding generator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_cnn = resnet.ResNet50(\n",
    "    weights=\"imagenet\", input_shape=imageDimensions, include_top=False\n",
    ")\n",
    "\n",
    "flatten = layers.Flatten()(base_cnn.output)\n",
    "dense1 = layers.Dense(512, activation=\"relu\")(flatten)\n",
    "dense1 = layers.BatchNormalization()(dense1)\n",
    "dense2 = layers.Dense(256, activation=\"relu\")(dense1)\n",
    "dense2 = layers.BatchNormalization()(dense2)\n",
    "output = layers.Dense(256)(dense2)\n",
    "\n",
    "embedding = Model(base_cnn.input, output, name=\"Embedding\")\n",
    "\n",
    "trainable = False\n",
    "for layer in base_cnn.layers:\n",
    "#     if layer.name == \"conv5_block1_out\":     ##TODO: Why only this layer?\n",
    "#         trainable = True\n",
    "    layer.trainable = trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B>Setting up the Siamese Network model</B>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistanceLayer(layers.Layer):\n",
    "    \"\"\"\n",
    "    This layer is responsible for computing the distance between the anchor\n",
    "    embedding and the positive embedding, and the anchor embedding and the\n",
    "    negative embedding.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, anchor, positive, negative):\n",
    "        ap_distance = tf.reduce_sum(tf.square(anchor - positive), -1)\n",
    "        an_distance = tf.reduce_sum(tf.square(anchor - negative), -1)\n",
    "        return (ap_distance, an_distance)\n",
    "\n",
    "\n",
    "anchor_input = layers.Input(name=\"anchor\", shape=imageDimensions)\n",
    "positive_input = layers.Input(name=\"positive\", shape=imageDimensions)\n",
    "negative_input = layers.Input(name=\"negative\", shape=imageDimensions)\n",
    "\n",
    "distances = DistanceLayer()(\n",
    "    embedding(resnet.preprocess_input(anchor_input)),   ##TODO : What is pre-process input do here?\n",
    "    embedding(resnet.preprocess_input(positive_input)),\n",
    "    embedding(resnet.preprocess_input(negative_input)),\n",
    ")\n",
    "\n",
    "siamese_network = Model(\n",
    "    inputs=[anchor_input, positive_input, negative_input], outputs=distances  ##TODO: Not clear what Output does here?\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Train Model - To Generate Embedding </b>\n",
    "<p>We now need to implement a model with custom training loop so we can compute the triplet loss using the three embeddings produced by the Siamese network.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseModel(Model):\n",
    "    \"\"\"The Siamese Network model with a custom training and testing loops.\n",
    "\n",
    "    Computes the triplet loss using the three embeddings produced by the\n",
    "    Siamese Network.\n",
    "\n",
    "    The triplet loss is defined as:\n",
    "       L(A, P, N) = max(‖f(A) - f(P)‖² - ‖f(A) - f(N)‖² + margin, 0)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, siamese_network, margin=0.5):\n",
    "        super(SiameseModel, self).__init__()\n",
    "        self.siamese_network = siamese_network\n",
    "        self.margin = margin\n",
    "        self.loss_tracker = metrics.Mean(name=\"loss\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.siamese_network(inputs)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # GradientTape is a context manager that records every operation that\n",
    "        # you do inside. We are using it here to compute the loss so we can get\n",
    "        # the gradients and apply them using the optimizer specified in\n",
    "        # `compile()`.\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = self._compute_loss(data)\n",
    "\n",
    "        # Storing the gradients of the loss function with respect to the\n",
    "        # weights/parameters.\n",
    "        gradients = tape.gradient(loss, self.siamese_network.trainable_weights)\n",
    "\n",
    "        # Applying the gradients on the model using the specified optimizer\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(gradients, self.siamese_network.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Let's update and return the training loss metric.\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        loss = self._compute_loss(data)\n",
    "\n",
    "        # Let's update and return the loss metric.\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "\n",
    "         \n",
    "    def _compute_loss_sq(self, data):\n",
    "        # The output of the network is a tuple containing the distances\n",
    "        # between the anchor and the positive example, and the anchor and\n",
    "        # the negative example.\n",
    "        ap_distance, an_distance = self.siamese_network(data)\n",
    "\n",
    "        # Computing the Triplet Loss by subtracting both distances and\n",
    "        # making sure we don't get a negative value.\n",
    "        loss = ap_distance - an_distance\n",
    "        loss = tf.maximum(loss + self.margin, 0.0)\n",
    "        return loss\n",
    "    \n",
    "#     def _compute_loss_cos(self, data):\n",
    "#         cosine_similarity = metrics.CosineSimilarity()\n",
    "#         sitive_similarity = cosine_similarity(anchor_embedding, positive_embedding)\n",
    "#         print(\"Positive similarity:\", positive_similarity)\n",
    "#         negative_similarity = cosine_similarity(anchor_embedding, negative_embedding)\n",
    "#         print(\"Negative similarity\", negative_similarity)\n",
    "#         loss = tf.math.squared_difference(positive_similarity, negative_similarity)\n",
    "#         loss = tf.maximum(loss + self.margin, 0.0)\n",
    "#         #tf.math.squared_difference\n",
    "#         return loss\n",
    "\n",
    "    def _compute_loss(self, data):\n",
    "        return self._compute_loss_sq(data)\n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # We need to list our metrics here so the `reset_states()` can be\n",
    "        # called automatically.\n",
    "        return [self.loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "earlyStopping = EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=3,\n",
    "                              verbose=1)\n",
    "\n",
    "early_stop=[earlyStopping]\n",
    "siamese_model = SiameseModel(siamese_network)\n",
    "siamese_model.compile(optimizer=optimizers.Adam(0.0000001))\n",
    "siamese_model.fit(train_dataset, epochs=40, validation_data=val_dataset, callbacks=early_stop)  #8/8 - Changes from 20 to 40 to see if improve perf\n",
    "\n",
    "#Tuning\n",
    "# Image dimension=448, margin=0.5 epoch 1, norestraining of weights,Adam=0.0001, loss=2.1\n",
    "# Image dimension=224, margin=0.5 epoch 1, norestraining of weights,Adam=0.0001, loss=0.05\n",
    "# Image dimension=224, margin=0.5 epoch 1, norestraining of weights,Adam=0.0001, lossFn=cos, loss=? \n",
    "# Image dimension=224, margin=10 epoch 1, norestraining of weights,Adam=0.0001, loss=0.5\n",
    "# Image dimension=224, margin=0.5 epoch 1, norestraining of weights, Adam=0.00001 instead of 0.0001 loss=?**  0.000001 - 0.0020 - val_loss: 0.0095\n",
    "# Image dimension=112, margin=0.5 epoch 1, norestraining of weights,Adam=0.0001, loss=0.17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding.save(filename)\n",
    "siamese_network.save(filename2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_network = tf.keras.models.load_model(filename2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Generate/Compare Embedding related utility functions</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEmbeddings(row):\n",
    "    personId, anchor, positive, toCcompare, isGenuine, anchor_path, positive_path, toCcompare_path = row\n",
    "    return (\n",
    "        personId.numpy(), \n",
    "        embedding(resnet.preprocess_input(anchor)),\n",
    "        embedding(resnet.preprocess_input(positive)),\n",
    "        embedding(resnet.preprocess_input(toCcompare)),\n",
    "        isGenuine.numpy()\n",
    "        ,anchor_path.numpy()\n",
    "        ,positive_path.numpy()\n",
    "        ,toCcompare_path.numpy()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEmbeddingDataFrame(data_df, typeOfData):\n",
    "    dataset = prepareEvaluationData(data_df, typeOfData)\n",
    "    dataset = dataset.batch(1, drop_remainder=False)\n",
    "    embedding_data = [getEmbeddings(row) for row in iter(dataset)]\n",
    "    embeddings_data_df = pd.DataFrame(columns=[\"personId\", \"anchor_embedding\", \"positive_embedding\",\"negative_embedding\",\"isGenuine\", \"Anchor_Path\", \"Pos_Path\", \"ToComparePath\"], data=embedding_data)\n",
    "    return embeddings_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareEmbeds_row_cosine (personId, anchor_embedding, positive_embedding, negative_embedding, isGenuine):\n",
    "    cosine_similarity = metrics.CosineSimilarity()\n",
    "\n",
    "    positive_similarity = cosine_similarity(anchor_embedding, positive_embedding)\n",
    "    #print(\"Positive similarity:\", positive_similarity.numpy())\n",
    "\n",
    "    negative_similarity = cosine_similarity(anchor_embedding, negative_embedding)\n",
    "    #print(\"Negative similarity\", negative_similarity.numpy())\n",
    "    return (positive_similarity.numpy(), negative_similarity.numpy(), (positive_similarity.numpy() - negative_similarity.numpy()))\n",
    "\n",
    "def compareEmbeds_row_kMeansdistance (personId, anchor_embedding, positive_embedding, negative_embedding, isGenuine):\n",
    "        ap_distance = tf.reduce_sum(tf.square(anchor_embedding - positive_embedding), -1)\n",
    "        an_distance = tf.reduce_sum(tf.square(anchor_embedding - negative_embedding), -1)\n",
    "        return (ap_distance, an_distance, (ap_distance-an_distance))\n",
    "\n",
    "def compareEmbeds(df):\n",
    "    df2 = df.apply(lambda row: compareEmbeds_row_kMeansdistance(row.personId, row.anchor_embedding, row.positive_embedding, row.negative_embedding, row.isGenuine), axis=1,  result_type='expand')\n",
    "    df2.columns = [\"Pos\", \"Neg\", \"Diff\"]\n",
    "\n",
    "    df[[\"Pos\", \"Neg\", \"Diff\"]]=df2[[\"Pos\", \"Neg\", \"Diff\"]]\n",
    "    df[\"personId\"]=df[\"personId\"].apply(lambda x: x[0])\n",
    "    df[\"isGenuine\"]=df[\"isGenuine\"].apply(lambda x: x[0])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Train Decision Model</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[3,3,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Add]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-50b1bc57e9a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m##Load model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    210\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m   raise IOError(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, compile, options)\u001b[0m\n\u001b[1;32m    136\u001b[0m   \u001b[0;31m# Recreate layers and metrics using the info stored in the metadata.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mkeras_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKerasObjectLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_graph_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m   \u001b[0mkeras_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m   \u001b[0;31m# Generate a dictionary of all loaded nodes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/load.py\u001b[0m in \u001b[0;36mload_layers\u001b[0;34m(self, compile)\u001b[0m\n\u001b[1;32m    374\u001b[0m       self.loaded_nodes[node_metadata.node_id] = self._load_layer(\n\u001b[1;32m    375\u001b[0m           \u001b[0mnode_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m           node_metadata.metadata)\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnode_metadata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetric_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/load.py\u001b[0m in \u001b[0;36m_load_layer\u001b[0;34m(self, node_id, identifier, metadata)\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0;31m# Detect whether this object can be revived from the config. If not, then\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[0;31m# revive from the SavedModel instead.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m     \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msetter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_revive_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m       \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msetter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrevive_custom_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/load.py\u001b[0m in \u001b[0;36m_revive_from_config\u001b[0;34m(self, identifier, metadata, node_id)\u001b[0m\n\u001b[1;32m    433\u001b[0m       obj = (\n\u001b[1;32m    434\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_revive_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m           self._revive_layer_from_config(metadata, node_id))\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/load.py\u001b[0m in \u001b[0;36m_revive_layer_from_config\u001b[0;34m(self, metadata, node_id)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0mbuild_input_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'build_input_shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m     \u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_build_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_input_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/load.py\u001b[0m in \u001b[0;36m_try_build_layer\u001b[0;34m(self, obj, node_id, build_input_shape)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbuild_input_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m       \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuild_input_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m       \u001b[0mbase_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_input_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         dtype=self.dtype)\n\u001b[0m\u001b[1;32m    206\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m       self.bias = self.add_weight(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m         caching_device=caching_device)\n\u001b[0m\u001b[1;32m    640\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mregularizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m       \u001b[0;31m# TODO(fchollet): in the future, this should be handled at the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m         \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m         **kwargs_for_getter)\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m     \u001b[0;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36mmake_variable\u001b[0;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[1;32m    140\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m       \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m       shape=variable_shape if variable_shape else None)\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariableV1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_variable_v1_call\u001b[0;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m   def _variable_v2_call(cls,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m                         shape=None):\n\u001b[1;32m    198\u001b[0m     \u001b[0;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m     \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_variable_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   2616\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2617\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2618\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m   2619\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2620\u001b[0m     return variables.RefVariable(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m   1583\u001b[0m           \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m           \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1585\u001b[0;31m           distribute_strategy=distribute_strategy)\n\u001b[0m\u001b[1;32m   1586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1587\u001b[0m   def _init_from_args(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[0;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[1;32m   1710\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initializer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minit_from_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1712\u001b[0;31m               \u001b[0minitial_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1713\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCheckpointInitialValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_initialize_trackable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers/initializers_v2.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    408\u001b[0m     \"\"\"\n\u001b[1;32m    409\u001b[0m     return super(VarianceScaling, self).__call__(\n\u001b[0;32m--> 410\u001b[0;31m         shape, dtype=_get_dtype(dtype), **kwargs)\n\u001b[0m\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops_v2.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m       \u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_random_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops_v2.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(self, shape, minval, maxval, dtype)\u001b[0m\n\u001b[1;32m   1080\u001b[0m       \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m     return op(\n\u001b[0;32m-> 1082\u001b[0;31m         shape=shape, minval=minval, maxval=maxval, dtype=dtype, seed=self.seed)\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtruncated_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[1;32m    306\u001b[0m           \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmaxval\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mminval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m     \u001b[0;31m# TODO(b/132092188): C++ shape inference inside functional ops does not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;31m# cross FuncGraph boundaries since that information is only available in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    325\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6860\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6861\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6862\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6863\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[3,3,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Add]"
     ]
    }
   ],
   "source": [
    "##Load model\n",
    "embedding = tf.keras.models.load_model(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embeddings_data_df_train = getEmbeddingDataFrame(data_train, \"train\")\n",
    "embeddings_data_df_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pFile_embeddings_train, 'wb') as file:\n",
    "    pickle.dump(embeddings_data_df_train, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20798, 8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(pFile_embeddings_train, 'rb') as file:\n",
    "    df = pickle.load(file)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personId</th>\n",
       "      <th>anchor_embedding</th>\n",
       "      <th>positive_embedding</th>\n",
       "      <th>negative_embedding</th>\n",
       "      <th>isGenuine</th>\n",
       "      <th>Anchor_Path</th>\n",
       "      <th>Pos_Path</th>\n",
       "      <th>ToComparePath</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Neg</th>\n",
       "      <th>Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>((tf.Tensor(0.19811925, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.22750023, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.3195522, shape=(), dtype=float32...</td>\n",
       "      <td>False</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>(tf.Tensor(2.1321304, shape=(), dtype=float32))</td>\n",
       "      <td>(tf.Tensor(3.466082, shape=(), dtype=float32))</td>\n",
       "      <td>(tf.Tensor(-1.3339517, shape=(), dtype=float32))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>((tf.Tensor(0.19811925, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.22750023, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.4272677, shape=(), dtype=float32...</td>\n",
       "      <td>False</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>(tf.Tensor(2.1321304, shape=(), dtype=float32))</td>\n",
       "      <td>(tf.Tensor(6.6205983, shape=(), dtype=float32))</td>\n",
       "      <td>(tf.Tensor(-4.488468, shape=(), dtype=float32))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>((tf.Tensor(0.19811925, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.22750023, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.17955683, shape=(), dtype=float3...</td>\n",
       "      <td>False</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>(tf.Tensor(2.1321304, shape=(), dtype=float32))</td>\n",
       "      <td>(tf.Tensor(3.6923869, shape=(), dtype=float32))</td>\n",
       "      <td>(tf.Tensor(-1.5602565, shape=(), dtype=float32))</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   personId                                   anchor_embedding  \\\n",
       "0         1  ((tf.Tensor(0.19811925, shape=(), dtype=float3...   \n",
       "1         1  ((tf.Tensor(0.19811925, shape=(), dtype=float3...   \n",
       "2         1  ((tf.Tensor(0.19811925, shape=(), dtype=float3...   \n",
       "\n",
       "                                  positive_embedding  \\\n",
       "0  ((tf.Tensor(0.22750023, shape=(), dtype=float3...   \n",
       "1  ((tf.Tensor(0.22750023, shape=(), dtype=float3...   \n",
       "2  ((tf.Tensor(0.22750023, shape=(), dtype=float3...   \n",
       "\n",
       "                                  negative_embedding  isGenuine  \\\n",
       "0  ((tf.Tensor(0.3195522, shape=(), dtype=float32...      False   \n",
       "1  ((tf.Tensor(0.4272677, shape=(), dtype=float32...      False   \n",
       "2  ((tf.Tensor(0.17955683, shape=(), dtype=float3...      False   \n",
       "\n",
       "                                         Anchor_Path  \\\n",
       "0  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "1  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "2  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "\n",
       "                                            Pos_Path  \\\n",
       "0  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "1  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "2  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "\n",
       "                                       ToComparePath  \\\n",
       "0  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "1  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "2  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "\n",
       "                                               Pos  \\\n",
       "0  (tf.Tensor(2.1321304, shape=(), dtype=float32))   \n",
       "1  (tf.Tensor(2.1321304, shape=(), dtype=float32))   \n",
       "2  (tf.Tensor(2.1321304, shape=(), dtype=float32))   \n",
       "\n",
       "                                               Neg  \\\n",
       "0   (tf.Tensor(3.466082, shape=(), dtype=float32))   \n",
       "1  (tf.Tensor(6.6205983, shape=(), dtype=float32))   \n",
       "2  (tf.Tensor(3.6923869, shape=(), dtype=float32))   \n",
       "\n",
       "                                               Diff  \n",
       "0  (tf.Tensor(-1.3339517, shape=(), dtype=float32))  \n",
       "1   (tf.Tensor(-4.488468, shape=(), dtype=float32))  \n",
       "2  (tf.Tensor(-1.5602565, shape=(), dtype=float32))  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare embedding with the anchor\n",
    "df = compareEmbeds(df)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personId</th>\n",
       "      <th>anchor_embedding</th>\n",
       "      <th>positive_embedding</th>\n",
       "      <th>negative_embedding</th>\n",
       "      <th>isGenuine</th>\n",
       "      <th>Anchor_Path</th>\n",
       "      <th>Pos_Path</th>\n",
       "      <th>ToComparePath</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Neg</th>\n",
       "      <th>Diff</th>\n",
       "      <th>isForgery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>((tf.Tensor(0.19811925, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.22750023, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.3195522, shape=(), dtype=float32...</td>\n",
       "      <td>False</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>(tf.Tensor(2.1321304, shape=(), dtype=float32))</td>\n",
       "      <td>(tf.Tensor(3.466082, shape=(), dtype=float32))</td>\n",
       "      <td>(tf.Tensor(-1.3339517, shape=(), dtype=float32))</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>((tf.Tensor(0.19811925, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.22750023, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.4272677, shape=(), dtype=float32...</td>\n",
       "      <td>False</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>(tf.Tensor(2.1321304, shape=(), dtype=float32))</td>\n",
       "      <td>(tf.Tensor(6.6205983, shape=(), dtype=float32))</td>\n",
       "      <td>(tf.Tensor(-4.488468, shape=(), dtype=float32))</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>((tf.Tensor(0.19811925, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.22750023, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.17955683, shape=(), dtype=float3...</td>\n",
       "      <td>False</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>(tf.Tensor(2.1321304, shape=(), dtype=float32))</td>\n",
       "      <td>(tf.Tensor(3.6923869, shape=(), dtype=float32))</td>\n",
       "      <td>(tf.Tensor(-1.5602565, shape=(), dtype=float32))</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   personId                                   anchor_embedding  \\\n",
       "0         1  ((tf.Tensor(0.19811925, shape=(), dtype=float3...   \n",
       "1         1  ((tf.Tensor(0.19811925, shape=(), dtype=float3...   \n",
       "2         1  ((tf.Tensor(0.19811925, shape=(), dtype=float3...   \n",
       "\n",
       "                                  positive_embedding  \\\n",
       "0  ((tf.Tensor(0.22750023, shape=(), dtype=float3...   \n",
       "1  ((tf.Tensor(0.22750023, shape=(), dtype=float3...   \n",
       "2  ((tf.Tensor(0.22750023, shape=(), dtype=float3...   \n",
       "\n",
       "                                  negative_embedding  isGenuine  \\\n",
       "0  ((tf.Tensor(0.3195522, shape=(), dtype=float32...      False   \n",
       "1  ((tf.Tensor(0.4272677, shape=(), dtype=float32...      False   \n",
       "2  ((tf.Tensor(0.17955683, shape=(), dtype=float3...      False   \n",
       "\n",
       "                                         Anchor_Path  \\\n",
       "0  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "1  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "2  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "\n",
       "                                            Pos_Path  \\\n",
       "0  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "1  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "2  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "\n",
       "                                       ToComparePath  \\\n",
       "0  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "1  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "2  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "\n",
       "                                               Pos  \\\n",
       "0  (tf.Tensor(2.1321304, shape=(), dtype=float32))   \n",
       "1  (tf.Tensor(2.1321304, shape=(), dtype=float32))   \n",
       "2  (tf.Tensor(2.1321304, shape=(), dtype=float32))   \n",
       "\n",
       "                                               Neg  \\\n",
       "0   (tf.Tensor(3.466082, shape=(), dtype=float32))   \n",
       "1  (tf.Tensor(6.6205983, shape=(), dtype=float32))   \n",
       "2  (tf.Tensor(3.6923869, shape=(), dtype=float32))   \n",
       "\n",
       "                                               Diff  isForgery  \n",
       "0  (tf.Tensor(-1.3339517, shape=(), dtype=float32))       True  \n",
       "1   (tf.Tensor(-4.488468, shape=(), dtype=float32))       True  \n",
       "2  (tf.Tensor(-1.5602565, shape=(), dtype=float32))       True  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_forgery = df.assign(isForgery=lambda x: (0 == x.isGenuine))\n",
    "df_train_forgery.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a logistic regression model for predictions\n",
    "#lr = LogisticRegression(random_state=0).fit(df[[\"personId\", \"Pos\", \"Neg\"]], df[\"isGenuine\"])\n",
    "lr = LogisticRegression(random_state=0).fit(df_train_forgery[[\"personId\", \"Pos\", \"Neg\"]], df_train_forgery[\"isForgery\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pFile_lrmodel, 'wb') as file:\n",
    "    pickle.dump(lr, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pFile_lrmodel, 'rb') as file:\n",
    "    lr = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict = lr.predict(df_train_forgery[[\"personId\", \"Pos\", \"Neg\"]])  #neg = tocompare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.921605"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fpr, tpr, thresholds = metrics.roc_curve(df[\"isGenuine\"], y_train_predict, pos_label=2)\n",
    "# metrics.auc(fpr, tpr)\n",
    "m_train = metrics.AUC()\n",
    "m_train.update_state(df_train_forgery[\"isForgery\"], y_train_predict)\n",
    "m_train.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[10318,   638],\n",
       "       [  970,  8872]], dtype=int32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#metrics.confusion_matrix(df[\"isGenuine\"], y_train_predict)\n",
    "tf.math.confusion_matrix(df_train_forgery[\"isForgery\"], y_train_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Testing</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting what the network has learned\n",
    "At this point, we can check how the network learned to separate the embeddings depending on whether they belong to similar images.\n",
    "\n",
    "We can use cosine similarity to measure the similarity between embeddings.\n",
    "\n",
    "Let's pick a sample from the dataset to check the similarity between the embeddings generated for each image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can compute the cosine similarity between the anchor and positive images and compare it with the similarity between the anchor and the negative images.\n",
    "\n",
    "We should expect the similarity between the anchor and positive images to be larger than the similarity between the anchor and the negative images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Load model\n",
    "embedding = tf.keras.models.load_model(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_data_df_tst = getEmbeddingDataFrame(data_test, \"test\")\n",
    "embeddings_data_df_tst.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pFile_embeddings_tst, 'wb') as file:\n",
    "    pickle.dump(embeddings_data_df_tst, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5038, 8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(pFile_embeddings_tst, 'rb') as file:\n",
    "    df_tst = pickle.load(file)\n",
    "df_tst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personId</th>\n",
       "      <th>anchor_embedding</th>\n",
       "      <th>positive_embedding</th>\n",
       "      <th>negative_embedding</th>\n",
       "      <th>isGenuine</th>\n",
       "      <th>Anchor_Path</th>\n",
       "      <th>Pos_Path</th>\n",
       "      <th>ToComparePath</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Neg</th>\n",
       "      <th>Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>((tf.Tensor(0.1990531, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.18121363, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.10500425, shape=(), dtype=float3...</td>\n",
       "      <td>False</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>(tf.Tensor(1.3259882, shape=(), dtype=float32))</td>\n",
       "      <td>(tf.Tensor(8.532532, shape=(), dtype=float32))</td>\n",
       "      <td>(tf.Tensor(-7.2065434, shape=(), dtype=float32))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>((tf.Tensor(0.1990531, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.18121363, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.2641765, shape=(), dtype=float32...</td>\n",
       "      <td>False</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>(tf.Tensor(1.3259882, shape=(), dtype=float32))</td>\n",
       "      <td>(tf.Tensor(1.699486, shape=(), dtype=float32))</td>\n",
       "      <td>(tf.Tensor(-0.37349784, shape=(), dtype=float32))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>((tf.Tensor(0.1990531, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.18121363, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.050875347, shape=(), dtype=float...</td>\n",
       "      <td>False</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>(tf.Tensor(1.3259882, shape=(), dtype=float32))</td>\n",
       "      <td>(tf.Tensor(5.999592, shape=(), dtype=float32))</td>\n",
       "      <td>(tf.Tensor(-4.6736035, shape=(), dtype=float32))</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   personId                                   anchor_embedding  \\\n",
       "0        49  ((tf.Tensor(0.1990531, shape=(), dtype=float32...   \n",
       "1        49  ((tf.Tensor(0.1990531, shape=(), dtype=float32...   \n",
       "2        49  ((tf.Tensor(0.1990531, shape=(), dtype=float32...   \n",
       "\n",
       "                                  positive_embedding  \\\n",
       "0  ((tf.Tensor(0.18121363, shape=(), dtype=float3...   \n",
       "1  ((tf.Tensor(0.18121363, shape=(), dtype=float3...   \n",
       "2  ((tf.Tensor(0.18121363, shape=(), dtype=float3...   \n",
       "\n",
       "                                  negative_embedding  isGenuine  \\\n",
       "0  ((tf.Tensor(0.10500425, shape=(), dtype=float3...      False   \n",
       "1  ((tf.Tensor(0.2641765, shape=(), dtype=float32...      False   \n",
       "2  ((tf.Tensor(0.050875347, shape=(), dtype=float...      False   \n",
       "\n",
       "                                         Anchor_Path  \\\n",
       "0  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "1  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "2  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "\n",
       "                                            Pos_Path  \\\n",
       "0  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "1  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "2  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "\n",
       "                                       ToComparePath  \\\n",
       "0  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "1  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "2  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "\n",
       "                                               Pos  \\\n",
       "0  (tf.Tensor(1.3259882, shape=(), dtype=float32))   \n",
       "1  (tf.Tensor(1.3259882, shape=(), dtype=float32))   \n",
       "2  (tf.Tensor(1.3259882, shape=(), dtype=float32))   \n",
       "\n",
       "                                              Neg  \\\n",
       "0  (tf.Tensor(8.532532, shape=(), dtype=float32))   \n",
       "1  (tf.Tensor(1.699486, shape=(), dtype=float32))   \n",
       "2  (tf.Tensor(5.999592, shape=(), dtype=float32))   \n",
       "\n",
       "                                                Diff  \n",
       "0   (tf.Tensor(-7.2065434, shape=(), dtype=float32))  \n",
       "1  (tf.Tensor(-0.37349784, shape=(), dtype=float32))  \n",
       "2   (tf.Tensor(-4.6736035, shape=(), dtype=float32))  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tst = compareEmbeds(df_tst)\n",
    "df_tst.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personId</th>\n",
       "      <th>anchor_embedding</th>\n",
       "      <th>positive_embedding</th>\n",
       "      <th>negative_embedding</th>\n",
       "      <th>isGenuine</th>\n",
       "      <th>Anchor_Path</th>\n",
       "      <th>Pos_Path</th>\n",
       "      <th>ToComparePath</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Neg</th>\n",
       "      <th>Diff</th>\n",
       "      <th>isForgery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>((tf.Tensor(0.1990531, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.18121363, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.10500425, shape=(), dtype=float3...</td>\n",
       "      <td>False</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>(tf.Tensor(1.3259882, shape=(), dtype=float32))</td>\n",
       "      <td>(tf.Tensor(8.532532, shape=(), dtype=float32))</td>\n",
       "      <td>(tf.Tensor(-7.2065434, shape=(), dtype=float32))</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>((tf.Tensor(0.1990531, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.18121363, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.2641765, shape=(), dtype=float32...</td>\n",
       "      <td>False</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>(tf.Tensor(1.3259882, shape=(), dtype=float32))</td>\n",
       "      <td>(tf.Tensor(1.699486, shape=(), dtype=float32))</td>\n",
       "      <td>(tf.Tensor(-0.37349784, shape=(), dtype=float32))</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>((tf.Tensor(0.1990531, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.18121363, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.050875347, shape=(), dtype=float...</td>\n",
       "      <td>False</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>(tf.Tensor(1.3259882, shape=(), dtype=float32))</td>\n",
       "      <td>(tf.Tensor(5.999592, shape=(), dtype=float32))</td>\n",
       "      <td>(tf.Tensor(-4.6736035, shape=(), dtype=float32))</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>((tf.Tensor(0.1990531, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.18121363, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.23118632, shape=(), dtype=float3...</td>\n",
       "      <td>False</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>(tf.Tensor(1.3259882, shape=(), dtype=float32))</td>\n",
       "      <td>(tf.Tensor(6.6176825, shape=(), dtype=float32))</td>\n",
       "      <td>(tf.Tensor(-5.291694, shape=(), dtype=float32))</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>((tf.Tensor(0.1990531, shape=(), dtype=float32...</td>\n",
       "      <td>((tf.Tensor(0.18121363, shape=(), dtype=float3...</td>\n",
       "      <td>((tf.Tensor(0.3431577, shape=(), dtype=float32...</td>\n",
       "      <td>False</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>[b'/notebooks/capstone/dataset/dataset2/sign_d...</td>\n",
       "      <td>(tf.Tensor(1.3259882, shape=(), dtype=float32))</td>\n",
       "      <td>(tf.Tensor(7.832204, shape=(), dtype=float32))</td>\n",
       "      <td>(tf.Tensor(-6.5062156, shape=(), dtype=float32))</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   personId                                   anchor_embedding  \\\n",
       "0        49  ((tf.Tensor(0.1990531, shape=(), dtype=float32...   \n",
       "1        49  ((tf.Tensor(0.1990531, shape=(), dtype=float32...   \n",
       "2        49  ((tf.Tensor(0.1990531, shape=(), dtype=float32...   \n",
       "3        49  ((tf.Tensor(0.1990531, shape=(), dtype=float32...   \n",
       "4        49  ((tf.Tensor(0.1990531, shape=(), dtype=float32...   \n",
       "\n",
       "                                  positive_embedding  \\\n",
       "0  ((tf.Tensor(0.18121363, shape=(), dtype=float3...   \n",
       "1  ((tf.Tensor(0.18121363, shape=(), dtype=float3...   \n",
       "2  ((tf.Tensor(0.18121363, shape=(), dtype=float3...   \n",
       "3  ((tf.Tensor(0.18121363, shape=(), dtype=float3...   \n",
       "4  ((tf.Tensor(0.18121363, shape=(), dtype=float3...   \n",
       "\n",
       "                                  negative_embedding  isGenuine  \\\n",
       "0  ((tf.Tensor(0.10500425, shape=(), dtype=float3...      False   \n",
       "1  ((tf.Tensor(0.2641765, shape=(), dtype=float32...      False   \n",
       "2  ((tf.Tensor(0.050875347, shape=(), dtype=float...      False   \n",
       "3  ((tf.Tensor(0.23118632, shape=(), dtype=float3...      False   \n",
       "4  ((tf.Tensor(0.3431577, shape=(), dtype=float32...      False   \n",
       "\n",
       "                                         Anchor_Path  \\\n",
       "0  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "1  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "2  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "3  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "4  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "\n",
       "                                            Pos_Path  \\\n",
       "0  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "1  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "2  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "3  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "4  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "\n",
       "                                       ToComparePath  \\\n",
       "0  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "1  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "2  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "3  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "4  [b'/notebooks/capstone/dataset/dataset2/sign_d...   \n",
       "\n",
       "                                               Pos  \\\n",
       "0  (tf.Tensor(1.3259882, shape=(), dtype=float32))   \n",
       "1  (tf.Tensor(1.3259882, shape=(), dtype=float32))   \n",
       "2  (tf.Tensor(1.3259882, shape=(), dtype=float32))   \n",
       "3  (tf.Tensor(1.3259882, shape=(), dtype=float32))   \n",
       "4  (tf.Tensor(1.3259882, shape=(), dtype=float32))   \n",
       "\n",
       "                                               Neg  \\\n",
       "0   (tf.Tensor(8.532532, shape=(), dtype=float32))   \n",
       "1   (tf.Tensor(1.699486, shape=(), dtype=float32))   \n",
       "2   (tf.Tensor(5.999592, shape=(), dtype=float32))   \n",
       "3  (tf.Tensor(6.6176825, shape=(), dtype=float32))   \n",
       "4   (tf.Tensor(7.832204, shape=(), dtype=float32))   \n",
       "\n",
       "                                                Diff  isForgery  \n",
       "0   (tf.Tensor(-7.2065434, shape=(), dtype=float32))       True  \n",
       "1  (tf.Tensor(-0.37349784, shape=(), dtype=float32))       True  \n",
       "2   (tf.Tensor(-4.6736035, shape=(), dtype=float32))       True  \n",
       "3    (tf.Tensor(-5.291694, shape=(), dtype=float32))       True  \n",
       "4   (tf.Tensor(-6.5062156, shape=(), dtype=float32))       True  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_forgery = df_tst.assign(isForgery=lambda x: (0 == x.isGenuine))\n",
    "df_test_forgery.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tst_predict = lr.predict(df_test_forgery[[\"personId\", \"Pos\", \"Neg\"]])  #neg = tocompare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8812107"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn import metrics\n",
    "# fpr_tst, tpr_tst, thresholds_tst = metrics.roc_curve(df_tst[\"isGenuine\"], y_tst_predict, pos_label=2)\n",
    "# metrics.auc(fpr_tst, tpr_tst)\n",
    "m_tst = metrics.AUC()\n",
    "m_tst.update_state(df_test_forgery[\"isForgery\"], y_tst_predict)\n",
    "m_tst.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[2127,  183],\n",
       "       [ 432, 2296]], dtype=int32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#metrics.confusion_matrix(df_tst[\"isGenuine\"], y_tst_predict)\n",
    "tf.math.confusion_matrix(df_test_forgery[\"isForgery\"], y_tst_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8416422"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_tst_recall = metrics.Recall()\n",
    "m_tst_recall.update_state(df_test_forgery[\"isForgery\"], y_tst_predict)\n",
    "m_tst_recall.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9261799"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_tst_precision = metrics.Precision()\n",
    "m_tst_precision.update_state(df_test_forgery[\"isForgery\"], y_tst_predict)\n",
    "m_tst_precision.result().numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
